# enhanced_video_assistant_v44.py
"""
Enhanced Video Assistant V4.4 - Complete Voice Integration
AI-powered video creation with professional voice narration and Chennai business context
"""

import asyncio
import logging
import os
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

# Video creation components
try:
    from video_engine_bridge import video_bridge
    VIDEO_ENGINE_AVAILABLE = video_bridge.is_available
except ImportError:
    VIDEO_ENGINE_AVAILABLE = False

# Voice services
try:
    from azure_speech_service_v44 import AzureSpeechService
    VOICE_SERVICE_AVAILABLE = True
except ImportError:
    VOICE_SERVICE_AVAILABLE = False

class EnhancedVideoAssistantV44:
    """Complete AI-Powered Video Assistant with Voice Integration"""
    
    def __init__(self):
        self.setup_logging()
        
        # Initialize video engine
        if VIDEO_ENGINE_AVAILABLE:
            self.video_engine = video_bridge
            self.logger.info("âœ… Enhanced Video Engine V4.3 loaded")
        else:
            self.video_engine = None
            self.logger.warning("âš ï¸ Video engine not available")
        
        # Initialize voice service
        if VOICE_SERVICE_AVAILABLE:
            self.voice_service = AzureSpeechService()
            self.logger.info("âœ… Azure Speech Service V4.4 loaded")
        else:
            self.voice_service = None
            self.logger.warning("âš ï¸ Voice service not available")
        
        # Directories
        self.voice_videos_dir = Path("voice_enhanced_videos")
        self.voice_videos_dir.mkdir(exist_ok=True)
        
        # Enhanced templates for voice-enabled videos
        self.voice_enabled_templates = {
            'business_presentation': {
                'title_template': 'Professional Business Presentation: {topic}',
                'personas': ['professional', 'authoritative'],
                'scene_count': 6,
                'duration_per_scene': 45,
                'style': 'corporate_professional',
                'voice_intro': "Welcome to our comprehensive presentation on {topic}. Let's explore the key insights and opportunities.",
                'voice_outro': "Thank you for your attention. Let's discuss how we can implement these strategies for your business success."
            },
            'tech_showcase': {
                'title_template': 'Technology Innovation Showcase: {topic}',
                'personas': ['enthusiastic', 'professional'],
                'scene_count': 5,
                'duration_per_scene': 50,
                'style': 'tech_modern',
                'voice_intro': "Get ready to discover cutting-edge technology that's transforming {topic}. This is truly exciting!",
                'voice_outro': "The future is here, and it's powered by innovation. Let's harness this technology for remarkable results."
            },
            'financial_education': {
                'title_template': 'Financial Education Series: {topic}',
                'personas': ['authoritative', 'friendly'],
                'scene_count': 4,
                'duration_per_scene': 60,
                'style': 'finance_professional',
                'voice_intro': "Welcome to our financial education series. Today we'll master the fundamentals of {topic}.",
                'voice_outro': "Remember, successful investing requires knowledge, patience, and disciplined execution. Start your journey today."
            },
            'chennai_business': {
                'title_template': 'Chennai Business Insights: {topic}',
                'personas': ['friendly', 'professional'],
                'scene_count': 5,
                'duration_per_scene': 40,
                'style': 'chennai_professional',
                'voice_intro': "Vanakkam! Let's explore exciting business opportunities in Chennai's dynamic market, focusing on {topic}.",
                'voice_outro': "Chennai's business landscape offers tremendous potential. Let's seize these opportunities together."
            },
            'social_impact': {
                'title_template': 'Social Impact Initiative: {topic}',
                'personas': ['enthusiastic', 'friendly'],
                'scene_count': 4,
                'duration_per_scene': 35,
                'style': 'social_warm',
                'voice_intro': "Join us in making a positive difference! Today we're focusing on {topic} and its transformative impact.",
                'voice_outro': "Together, we can create meaningful change. Every action counts toward building a better future."
            }
        }
        
        # Enhanced quality presets for voice videos
        self.voice_quality_presets = {
            'presentation_quality': {
                'resolution': (1920, 1080),
                'bitrate': 6000000,
                'audio_bitrate': 192000,
                'fps': 30,
                'description': 'High-quality for business presentations and client demos'
            },
            'web_optimized': {
                'resolution': (1280, 720),
                'bitrate': 2500000,
                'audio_bitrate': 128000,
                'fps': 25,
                'description': 'Optimized for web sharing and social media'
            },
            'mobile_friendly': {
                'resolution': (854, 480),
                'bitrate': 1200000,
                'audio_bitrate': 96000,
                'fps': 24,
                'description': 'Compact size for mobile sharing and WhatsApp'
            }
        }
        
        self.logger.info("ðŸŽ¬ðŸ—£ï¸ Enhanced Video Assistant V4.4 with Voice Integration ready!")
        
    def setup_logging(self):
        """Setup logging"""
        self.logger = logging.getLogger('EnhancedVideoAssistantV44')
        self.logger.setLevel(logging.INFO)
        
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    async def create_voice_enhanced_video(self, topic: str, template: str = "business_presentation",
                                        persona: str = "professional", quality: str = "presentation_quality") -> Dict[str, Any]:
        """Create complete video with professional voice narration"""
        
        start_time = datetime.now()
        self.logger.info(f"ðŸŽ¬ðŸ—£ï¸ Creating voice-enhanced video: {topic}")
        self.logger.info(f"   Template: {template}")
        self.logger.info(f"   Voice Persona: {persona}")
        self.logger.info(f"   Quality: {quality}")
        
        try:
            # Step 1: Generate enhanced script
            script = await self._generate_voice_script(topic, template)
            if not script:
                return self._failed_response("Script generation failed", start_time)
            
            # Step 2: Create video assets (slides)
            if not self.video_engine:
                return self._failed_response("Video engine not available", start_time)
            
            self.logger.info("ðŸŽ¥ Step 2: Creating video slides...")
            video_result = self.video_engine.create_enhanced_video_with_opencv(
                script, template, quality
            )
            
            if not video_result:
                return self._failed_response("Video creation failed", start_time)
            
            # Step 3: Generate voice narration
            if not self.voice_service:
                self.logger.warning("âš ï¸ Voice service not available, creating video without narration")
                return self._video_only_response(video_result, script, start_time)
            
            self.logger.info(f"ðŸ—£ï¸ Step 3: Generating voice narration with {persona} persona...")
            narration_result = await self.voice_service.create_video_narration(script, persona)
            
            # Step 4: Combine video and voice (future enhancement)
            # For now, return both video and voice files separately
            combined_result = self._combine_results(video_result, narration_result, script, start_time)
            
            return combined_result
            
        except Exception as e:
            self.logger.error(f"âŒ Voice-enhanced video creation failed: {e}")
            return self._failed_response(str(e), start_time)
    
    async def _generate_voice_script(self, topic: str, template: str) -> Optional[Dict]:
        """Generate enhanced script optimized for voice narration"""
        
        try:
            template_config = self.voice_enabled_templates.get(template, 
                                                             self.voice_enabled_templates['business_presentation'])
            
            # Create enhanced script with voice optimization
            script = {
                "title": template_config['title_template'].format(topic=topic),
                "total_duration": template_config['scene_count'] * template_config['duration_per_scene'],
                "target_audience": "Business professionals and decision makers",
                "voice_persona": template_config['personas'][0],
                "style": template_config['style'],
                "scenes": []
            }
            
            # Generate introduction scene
            intro_scene = {
                "slide_text": f"{script['title']}\nPowered by Rudh AI",
                "narration": template_config['voice_intro'].format(topic=topic),
                "duration": template_config['duration_per_scene'],
                "scene_type": "intro"
            }
            script["scenes"].append(intro_scene)
            
            # Generate content scenes based on template
            content_scenes = self._generate_content_scenes(topic, template_config)
            script["scenes"].extend(content_scenes)
            
            # Generate conclusion scene
            outro_scene = {
                "slide_text": f"Thank You\nNext Steps & Discussion",
                "narration": template_config['voice_outro'].format(topic=topic),
                "duration": template_config['duration_per_scene'],
                "scene_type": "outro"
            }
            script["scenes"].append(outro_scene)
            
            self.logger.info(f"âœ… Enhanced script generated: {len(script['scenes'])} scenes")
            return script
            
        except Exception as e:
            self.logger.error(f"âŒ Script generation failed: {e}")
            return None
    
    def _generate_content_scenes(self, topic: str, template_config: Dict) -> List[Dict]:
        """Generate content scenes based on template and topic"""
        
        scenes = []
        scene_count = template_config['scene_count'] - 2  # Exclude intro and outro
        
        # Create content scenes based on topic and template style
        if 'AI' in topic or 'artificial intelligence' in topic.lower():
            scenes = self._generate_ai_scenes(topic, template_config, scene_count)
        elif 'portfolio' in topic.lower() or 'investment' in topic.lower():
            scenes = self._generate_finance_scenes(topic, template_config, scene_count)
        elif 'chennai' in topic.lower() or 'business' in topic.lower():
            scenes = self._generate_chennai_business_scenes(topic, template_config, scene_count)
        else:
            scenes = self._generate_generic_scenes(topic, template_config, scene_count)
        
        return scenes
    
    def _generate_ai_scenes(self, topic: str, template_config: Dict, scene_count: int) -> List[Dict]:
        """Generate AI-focused content scenes"""
        ai_scenes = [
            {
                "slide_text": f"AI Revolution in {topic}\nTransforming Business Operations",
                "narration": f"Artificial Intelligence is revolutionizing {topic}, bringing unprecedented efficiency and innovation to business operations across Chennai and beyond.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Key AI Applications\nReal-World Implementation",
                "narration": f"Let's explore the most impactful AI applications in {topic}, focusing on practical implementations that deliver measurable results for Chennai businesses.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Benefits & ROI\nMeasurable Business Impact",
                "narration": f"The return on investment for AI in {topic} is remarkable. Companies implementing these solutions see 30-50% efficiency improvements within the first year.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Implementation Strategy\nYour AI Journey",
                "narration": f"Successful AI implementation in {topic} requires a strategic approach. Let's outline the steps to transform your business with artificial intelligence.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            }
        ]
        return ai_scenes[:scene_count]
    
    def _generate_finance_scenes(self, topic: str, template_config: Dict, scene_count: int) -> List[Dict]:
        """Generate finance-focused content scenes"""
        finance_scenes = [
            {
                "slide_text": f"Modern {topic} Strategies\nData-Driven Investment Approach",
                "narration": f"Modern {topic} leverages advanced analytics and market intelligence to optimize returns while managing risk effectively in today's dynamic markets.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Risk Management\nProtecting Your Investments",
                "narration": f"Effective risk management in {topic} is crucial for long-term success. We'll explore proven strategies to protect and grow your investment portfolio.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Market Opportunities\nChennai & Tamil Nadu Focus",
                "narration": f"Chennai's growing economy presents unique opportunities in {topic}. Local market knowledge combined with global best practices creates winning strategies.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            }
        ]
        return finance_scenes[:scene_count]
    
    def _generate_chennai_business_scenes(self, topic: str, template_config: Dict, scene_count: int) -> List[Dict]:
        """Generate Chennai business-focused content scenes"""
        chennai_scenes = [
            {
                "slide_text": f"Chennai Market Dynamics\n{topic} Opportunities",
                "narration": f"Chennai's thriving business ecosystem offers exceptional opportunities in {topic}. The city's strategic location and skilled workforce create competitive advantages.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Local Success Stories\nProven Results in {topic}",
                "narration": f"Several Chennai companies have achieved remarkable success in {topic}. These case studies demonstrate the potential for growth and innovation in our market.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Growth Strategies\nScaling Your {topic} Business",
                "narration": f"To succeed in Chennai's {topic} market, businesses need focused strategies that leverage local strengths while maintaining global competitiveness.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Future Outlook\nChennai's {topic} Potential",
                "narration": f"The future of {topic} in Chennai is incredibly bright. Government support, infrastructure development, and talent availability position us for exponential growth.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            }
        ]
        return chennai_scenes[:scene_count]
    
    def _generate_generic_scenes(self, topic: str, template_config: Dict, scene_count: int) -> List[Dict]:
        """Generate generic content scenes for any topic"""
        generic_scenes = [
            {
                "slide_text": f"Understanding {topic}\nFoundational Concepts",
                "narration": f"Let's begin by establishing a solid understanding of {topic} and its fundamental principles that drive success in today's business environment.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Key Benefits\nWhy {topic} Matters",
                "narration": f"The strategic importance of {topic} cannot be overstated. Organizations that excel in this area consistently outperform their competitors.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Best Practices\nProven Strategies for {topic}",
                "narration": f"Industry leaders have developed proven best practices for {topic}. These strategies have been tested across various markets and consistently deliver results.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            },
            {
                "slide_text": f"Implementation\nYour Next Steps in {topic}",
                "narration": f"Successful implementation of {topic} requires careful planning and execution. Let's outline the practical steps to achieve your objectives.",
                "duration": template_config['duration_per_scene'],
                "scene_type": "content"
            }
        ]
        return generic_scenes[:scene_count]
    
    def _combine_results(self, video_result: str, narration_result: Dict, script: Dict, start_time: datetime) -> Dict[str, Any]:
        """Combine video and narration results"""
        
        duration = (datetime.now() - start_time).total_seconds()
        
        return {
            'success': True,
            'video_file': video_result,
            'narration_files': narration_result.get('narration_files', []),
            'script': script,
            'total_duration': duration,
            'voice_enabled': narration_result.get('success', False),
            'completed_scenes': narration_result.get('completed_scenes', 0),
            'total_scenes': narration_result.get('total_scenes', 0),
            'voice_persona': script.get('voice_persona', 'professional'),
            'template': script.get('style', 'business'),
            'timestamp': start_time.isoformat(),
            'features': [
                'Professional video slides',
                'Voice narration' if narration_result.get('success') else 'Voice narration (fallback)',
                'Chennai business context',
                'AI-powered script generation',
                'Multiple quality presets'
            ]
        }
    
    def _video_only_response(self, video_result: str, script: Dict, start_time: datetime) -> Dict[str, Any]:
        """Response for video-only creation (when voice service unavailable)"""
        
        duration = (datetime.now() - start_time).total_seconds()
        
        return {
            'success': True,
            'video_file': video_result,
            'narration_files': [],
            'script': script,
            'total_duration': duration,
            'voice_enabled': False,
            'voice_fallback': True,
            'template': script.get('style', 'business'),
            'timestamp': start_time.isoformat(),
            'features': [
                'Professional video slides',
                'AI-powered script generation',
                'Chennai business context',
                'Multiple quality presets',
                'Voice-ready (narration available in script)'
            ]
        }
    
    def _failed_response(self, error: str, start_time: datetime) -> Dict[str, Any]:
        """Response for failed video creation"""
        
        duration = (datetime.now() - start_time).total_seconds()
        
        return {
            'success': False,
            'error': error,
            'total_duration': duration,
            'timestamp': start_time.isoformat()
        }
    
    async def interactive_voice_video_session(self):
        """Interactive session for creating voice-enhanced videos"""
        
        print("\nðŸŽ¥ðŸ—£ï¸ RUDH ENHANCED VIDEO ASSISTANT V4.4 - VOICE-ENABLED VIDEO CREATION")
        print("=" * 80)
        print("ðŸŽ¯ CREATE PROFESSIONAL VIDEOS WITH AI-POWERED VOICE NARRATION")
        print("ðŸ—£ï¸ INDIAN ENGLISH VOICES WITH MULTIPLE PERSONAS")
        print("ðŸ¢ CHENNAI BUSINESS CONTEXT & TAMIL MARKET INSIGHTS")
        print("ðŸŽµ PROFESSIONAL TEMPLATES FOR EVERY BUSINESS NEED")
        print("=" * 80)
        
        # System status
        await self._display_system_status()
        
        while True:
            try:
                print("\n" + "="*60)
                request = input("\n[ðŸŽ¬ðŸ—£ï¸] Your voice video request (or 'help', 'quit'): ").strip()
                
                if not request:
                    continue
                
                if request.lower() in ['quit', 'exit', 'q']:
                    print("\nðŸ‘‹ Thank you for using Rudh Enhanced Video Assistant V4.4!")
                    break
                
                if request.lower() in ['help', '?']:
                    self._display_help()
                    continue
                
                if request.lower() == 'templates':
                    self._display_templates()
                    continue
                
                if request.lower() == 'voices':
                    await self._display_voice_personas()
                    continue
                
                if request.lower() == 'status':
                    await self._display_system_status()
                    continue
                
                # Parse and create voice-enhanced video
                await self._process_voice_video_request(request)
                
            except KeyboardInterrupt:
                print("\n\nðŸ‘‹ Session ended by user")
                break
            except Exception as e:
                print(f"\nâŒ Error: {e}")
    
    async def _process_voice_video_request(self, request: str):
        """Process voice video creation request"""
        
        # Parse request for enhanced video creation
        parsed = self._parse_enhanced_request(request)
        
        print(f"\nðŸŽ¯ VOICE-ENHANCED REQUEST PARSED:")
        print(f"   ðŸ“ Topic: {parsed['topic']}")
        print(f"   ðŸŽ¬ Template: {parsed['template']}")
        print(f"   ðŸ—£ï¸ Voice Persona: {parsed['persona']}")
        print(f"   ðŸ’Ž Quality: {parsed['quality']}")
        
        # Provide voice feedback if available
        if self.voice_service and self.voice_service.speech_connected:
            feedback_text = f"Creating voice-enhanced video about {parsed['topic']} using {parsed['persona']} persona."
            await self.voice_service.text_to_speech_with_persona(feedback_text, parsed['persona'], save_to_file=False)
        
        print(f"\nðŸŽ¬ CREATING VOICE-ENHANCED VIDEO")
        print(f"ðŸ“ Topic: {parsed['topic']}")
        print(f"ðŸŽ¨ Template: {parsed['template']}")
        print(f"ðŸ—£ï¸ Voice Persona: {parsed['persona']}")
        print(f"ðŸ’Ž Quality: {parsed['quality']}")
        
        start_time = time.time()
        
        # Create voice-enhanced video
        result = await self.create_voice_enhanced_video(
            parsed['topic'], 
            parsed['template'],
            parsed['persona'],
            parsed['quality']
        )
        
        creation_time = time.time() - start_time
        
        if result['success']:
            print(f"\nðŸŽ‰ VOICE-ENHANCED VIDEO CREATION SUCCESSFUL!")
            print(f"ðŸ“ Video File: {os.path.basename(result['video_file'])}")
            print(f"ðŸ—£ï¸ Voice Enabled: {'âœ…' if result['voice_enabled'] else 'âš ï¸ Fallback Mode'}")
            print(f"ðŸ“Š Completed Scenes: {result['completed_scenes']}/{result['total_scenes']}")
            print(f"â±ï¸ Creation Time: {creation_time:.1f}s")
            print(f"ðŸŽ¬ Voice Persona: {result['voice_persona']}")
            
            if result['narration_files']:
                print(f"\nðŸŽµ Voice Narration Files Created:")
                for narration in result['narration_files']:
                    print(f"   ðŸ“„ Scene {narration['scene']}: {os.path.basename(narration['audio_file'])}")
            
            print(f"\nðŸŒŸ Features Included:")
            for feature in result['features']:
                print(f"   âœ… {feature}")
        else:
            print(f"\nâŒ Video creation failed: {result.get('error', 'Unknown error')}")
    
    def _parse_enhanced_request(self, request: str) -> Dict[str, str]:
        """Parse enhanced video request"""
        
        request_lower = request.lower()
        
        # Extract topic (everything after common command words)
        topic = request
        for prefix in ['create', 'make', 'generate', 'video', 'enhanced', 'voice']:
            if request_lower.startswith(prefix):
                topic = request[len(prefix):].strip()
                break
        
        # Remove common words
        for word in ['video', 'about', 'on', 'for', 'with', 'enhanced', 'voice']:
            topic = topic.replace(word, ' ').strip()
        
        topic = ' '.join(topic.split())  # Clean up spaces
        
        if not topic:
            topic = "business strategy"
        
        # Determine template
        template = "business_presentation"  # default
        if any(word in request_lower for word in ['tech', 'technology', 'ai', 'artificial intelligence']):
            template = "tech_showcase"
        elif any(word in request_lower for word in ['finance', 'investment', 'portfolio', 'money']):
            template = "financial_education"
        elif any(word in request_lower for word in ['chennai', 'local', 'tamil nadu']):
            template = "chennai_business"
        elif any(word in request_lower for word in ['social', 'impact', 'community']):
            template = "social_impact"
        
        # Determine voice persona
        persona = "professional"  # default
        if any(word in request_lower for word in ['exciting', 'energetic', 'enthusiastic']):
            persona = "enthusiastic"
        elif any(word in request_lower for word in ['expert', 'authoritative', 'credible']):
            persona = "authoritative"
        elif any(word in request_lower for word in ['friendly', 'warm', 'approachable']):
            persona = "friendly"
        elif any(word in request_lower for word in ['tamil', 'local language']):
            persona = "tamil_friendly"
        
        # Determine quality
        quality = "presentation_quality"  # default
        if any(word in request_lower for word in ['web', 'social media', 'online']):
            quality = "web_optimized"
        elif any(word in request_lower for word in ['mobile', 'phone', 'whatsapp']):
            quality = "mobile_friendly"
        
        return {
            'topic': topic,
            'template': template,
            'persona': persona,
            'quality': quality
        }
    
    async def _display_system_status(self):
        """Display comprehensive system status"""
        
        print("\nðŸ“Š SYSTEM STATUS:")
        print(f"   ðŸŽ¬ Video Engine: {'âœ… Operational' if VIDEO_ENGINE_AVAILABLE else 'âŒ Not Available'}")
        print(f"   ðŸ—£ï¸ Voice Service: {'âœ… Operational' if VOICE_SERVICE_AVAILABLE else 'âŒ Not Available'}")
        
        if self.voice_service:
            voice_status = self.voice_service.get_service_status()
            print(f"   ðŸ”— Azure Speech: {'âœ… Connected' if voice_status['speech_connected'] else 'âŒ Disconnected'}")
            print(f"   ðŸŽµ Audio Playback: {'âœ… Available' if voice_status['pygame_available'] else 'âŒ Not Available'}")
        
        print(f"   ðŸ“ Output Directory: {self.voice_videos_dir}")
        print(f"   ðŸŽ¯ Templates Available: {len(self.voice_enabled_templates)}")
        print(f"   ðŸ—£ï¸ Voice Personas: {len(self.voice_service.voice_personas) if self.voice_service else 0}")
    
    def _display_templates(self):
        """Display available templates"""
        
        print("\nðŸŽ¬ AVAILABLE VOICE-ENABLED TEMPLATES:")
        print("=" * 60)
        
        for template_name, config in self.voice_enabled_templates.items():
            print(f"\nðŸ“‹ {template_name.upper()}")
            print(f"   ðŸŽ¯ Title: {config['title_template']}")
            print(f"   ðŸ—£ï¸ Voice Personas: {', '.join(config['personas'])}")
            print(f"   ðŸ“Š Scenes: {config['scene_count']}")
            print(f"   â±ï¸ Duration per Scene: {config['duration_per_scene']}s")
            print(f"   ðŸŽ¨ Style: {config['style']}")
    
    async def _display_voice_personas(self):
        """Display available voice personas"""
        
        print("\nðŸ—£ï¸ AVAILABLE VOICE PERSONAS:")
        print("=" * 60)
        
        if self.voice_service:
            voices = self.voice_service.get_available_voices()
            for voice in voices:
                print(f"\nðŸŽ­ {voice['persona'].upper()}")
                print(f"   ðŸ“ Description: {voice['description']}")
                print(f"   ðŸ—£ï¸ Voice: {voice['voice']}")
                print(f"   ðŸŒ Language: {voice['language']}")
                print(f"   ðŸ’¼ Best For: {voice['recommended_for']}")
        else:
            print("âš ï¸ Voice service not available")
    
    def _display_help(self):
        """Display help information"""
        
        print("\nðŸ†˜ ENHANCED VIDEO ASSISTANT V4.4 HELP")
        print("=" * 50)
        
        print("\nðŸŽ¬ Voice-Enhanced Video Creation:")
        print("   'Create enhanced video about AI portfolio management'")
        print("   'Make tech showcase for artificial intelligence'")
        print("   'Generate Chennai business presentation'")
        print("   'Create financial education video with authoritative voice'")
        
        print("\nðŸ”§ Utility Commands:")
        print("   'templates' - Show available video templates")
        print("   'voices' - Display voice personas and options")
        print("   'status' - System status and capabilities")
        print("   'help' - Show this help message")
        print("   'quit' - Exit the assistant")
        
        print("\nðŸŽ¯ Tips for Better Results:")
        print("   â€¢ Be specific about your topic")
        print("   â€¢ Mention voice style preferences (professional, enthusiastic, etc.)")
        print("   â€¢ Specify template type (business, tech, finance, Chennai)")
        print("   â€¢ Include quality preferences (presentation, web, mobile)")
        
        print("\nðŸŒŸ Example Commands:")
        print("   'Create professional presentation about AI in Chennai business'")
        print("   'Make enthusiastic tech showcase for machine learning'")
        print("   'Generate authoritative financial education about portfolio optimization'")
        print("   'Create friendly tutorial about investment strategies'")

# Test function
async def test_enhanced_video_assistant_v44():
    """Test Enhanced Video Assistant V4.4"""
    print("ðŸ§ª Testing Enhanced Video Assistant V4.4")
    print("=" * 55)
    
    assistant = EnhancedVideoAssistantV44()
    
    # Test status
    print("\nðŸ“Š Assistant Status:")
    await assistant._display_system_status()
    
    # Test voice-enhanced video creation
    print("\nðŸŽ¬ Testing Voice-Enhanced Video Creation:")
    
    test_result = await assistant.create_voice_enhanced_video(
        topic="AI Portfolio Management",
        template="financial_education",
        persona="professional",
        quality="presentation_quality"
    )
    
    if test_result['success']:
        print(f"   âœ… Voice-enhanced video creation successful!")
        print(f"   ðŸ“ Video file: {test_result['video_file']}")
        print(f"   ðŸ—£ï¸ Voice enabled: {test_result['voice_enabled']}")
        print(f"   ðŸ“Š Scenes completed: {test_result['completed_scenes']}/{test_result['total_scenes']}")
        print(f"   â±ï¸ Creation time: {test_result['total_duration']:.1f}s")
    else:
        print(f"   âŒ Video creation failed: {test_result.get('error')}")
    
    return assistant

if __name__ == "__main__":
    # Can be run either as test or interactive session
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'interactive':
        assistant = EnhancedVideoAssistantV44()
        asyncio.run(assistant.interactive_voice_video_session())
    else:
        asyncio.run(test_enhanced_video_assistant_v44())